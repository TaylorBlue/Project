{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFIT5010 Statistical Machine Learning Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import glob\n",
    "import spacy\n",
    "import re,string,unicodedata\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "from wordcloud import WordCloud,STOPWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import data #####\n",
    "#add a new column with value = 1 for train positive  \n",
    "train_pos = pd.read_csv('desktop/ML project/train_pos.csv')\n",
    "train_pos[\"sentiment\"] = \"1\"\n",
    "\n",
    "#add a new column with value = 0 for train negative \n",
    "train_neg = pd.read_csv('desktop/ML project/train_neg.csv')\n",
    "train_neg[\"sentiment\"] = \"0\"\n",
    "\n",
    "#add a new column with value = 1 for test positive \n",
    "test_pos = pd.read_csv('desktop/ML project/test_pos.csv')\n",
    "test_pos[\"sentiment\"] = \"1\"\n",
    "\n",
    "#add a new column with value = 0 for test negative \n",
    "test_neg = pd.read_csv('desktop/ML project/test_neg.csv')\n",
    "test_neg[\"sentiment\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>12495</td>\n",
       "      <td>Seeing as the vote average was pretty low, and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12496</th>\n",
       "      <td>12496</td>\n",
       "      <td>The plot had some wretched, unbelievable twist...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12497</th>\n",
       "      <td>12497</td>\n",
       "      <td>I am amazed at how this movie(and most others ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12498</th>\n",
       "      <td>12498</td>\n",
       "      <td>A Christmas Together actually came before my t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12499</th>\n",
       "      <td>12499</td>\n",
       "      <td>Working-class romantic drama from director Mar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                             Review sentiment\n",
       "0               0  Bromwell High is a cartoon comedy. It ran at t...         1\n",
       "1               1  Homelessness (or Houselessness as George Carli...         1\n",
       "2               2  Brilliant over-acting by Lesley Ann Warren. Be...         1\n",
       "3               3  This is easily the most underrated film inn th...         1\n",
       "4               4  This is not the typical Mel Brooks film. It wa...         1\n",
       "...           ...                                                ...       ...\n",
       "12495       12495  Seeing as the vote average was pretty low, and...         1\n",
       "12496       12496  The plot had some wretched, unbelievable twist...         1\n",
       "12497       12497  I am amazed at how this movie(and most others ...         1\n",
       "12498       12498  A Christmas Together actually came before my t...         1\n",
       "12499       12499  Working-class romantic drama from director Mar...         1\n",
       "\n",
       "[12500 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view data\n",
    "train_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>12495</td>\n",
       "      <td>I was extraordinarily impressed by this film. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12496</th>\n",
       "      <td>12496</td>\n",
       "      <td>Although I'm not a golf fan, I attended a snea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12497</th>\n",
       "      <td>12497</td>\n",
       "      <td>From the start of \"The Edge Of Love\", the view...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12498</th>\n",
       "      <td>12498</td>\n",
       "      <td>This movie, with all its complexity and subtle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12499</th>\n",
       "      <td>12499</td>\n",
       "      <td>I've seen this story before but my kids haven'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                             Review sentiment\n",
       "0               0  I went and saw this movie last night after bei...         1\n",
       "1               1  Actor turned director Bill Paxton follows up h...         1\n",
       "2               2  As a recreational golfer with some knowledge o...         1\n",
       "3               3  I saw this film in a sneak preview, and it is ...         1\n",
       "4               4  Bill Paxton has taken the true story of the 19...         1\n",
       "...           ...                                                ...       ...\n",
       "12495       12495  I was extraordinarily impressed by this film. ...         1\n",
       "12496       12496  Although I'm not a golf fan, I attended a snea...         1\n",
       "12497       12497  From the start of \"The Edge Of Love\", the view...         1\n",
       "12498       12498  This movie, with all its complexity and subtle...         1\n",
       "12499       12499  I've seen this story before but my kids haven'...         1\n",
       "\n",
       "[12500 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Story of a man who has unnatural feelings for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Airport '77 starts as a brand new luxury 747 p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>This film lacked something I couldn't put my f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Sorry everyone,,, I know this is supposed to b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>When I was little my parents took me along to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>12495</td>\n",
       "      <td>Towards the end of the movie, I felt it was to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12496</th>\n",
       "      <td>12496</td>\n",
       "      <td>This is the kind of movie that my enemies cont...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12497</th>\n",
       "      <td>12497</td>\n",
       "      <td>I saw 'Descent' last night at the Stockholm Fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12498</th>\n",
       "      <td>12498</td>\n",
       "      <td>Some films that you pick up for a pound turn o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12499</th>\n",
       "      <td>12499</td>\n",
       "      <td>This is one of the dumbest films, I've ever se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                             Review sentiment\n",
       "0               0  Story of a man who has unnatural feelings for ...         0\n",
       "1               1  Airport '77 starts as a brand new luxury 747 p...         0\n",
       "2               2  This film lacked something I couldn't put my f...         0\n",
       "3               3  Sorry everyone,,, I know this is supposed to b...         0\n",
       "4               4  When I was little my parents took me along to ...         0\n",
       "...           ...                                                ...       ...\n",
       "12495       12495  Towards the end of the movie, I felt it was to...         0\n",
       "12496       12496  This is the kind of movie that my enemies cont...         0\n",
       "12497       12497  I saw 'Descent' last night at the Stockholm Fi...         0\n",
       "12498       12498  Some films that you pick up for a pound turn o...         0\n",
       "12499       12499  This is one of the dumbest films, I've ever se...         0\n",
       "\n",
       "[12500 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>12495</td>\n",
       "      <td>I occasionally let my kids watch this garbage ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12496</th>\n",
       "      <td>12496</td>\n",
       "      <td>When all we have anymore is pretty much realit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12497</th>\n",
       "      <td>12497</td>\n",
       "      <td>The basic genre is a thriller intercut with an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12498</th>\n",
       "      <td>12498</td>\n",
       "      <td>Four things intrigued me as to this film - fir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12499</th>\n",
       "      <td>12499</td>\n",
       "      <td>David Bryce's comments nearby are exceptionall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                             Review sentiment\n",
       "0               0  Once again Mr. Costner has dragged out a movie...         0\n",
       "1               1  This is an example of why the majority of acti...         0\n",
       "2               2  First of all I hate those moronic rappers, who...         0\n",
       "3               3  Not even the Beatles could write songs everyon...         0\n",
       "4               4  Brass pictures (movies is not a fitting word f...         0\n",
       "...           ...                                                ...       ...\n",
       "12495       12495  I occasionally let my kids watch this garbage ...         0\n",
       "12496       12496  When all we have anymore is pretty much realit...         0\n",
       "12497       12497  The basic genre is a thriller intercut with an...         0\n",
       "12498       12498  Four things intrigued me as to this film - fir...         0\n",
       "12499       12499  David Bryce's comments nearby are exceptionall...         0\n",
       "\n",
       "[12500 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the train positive and train negative data \n",
    "train = [train_pos, train_neg]\n",
    "train = pd.concat(train, ignore_index = True)\n",
    "\n",
    "# combine the test positive and test negative data \n",
    "test = [test_pos, test_neg]\n",
    "test = pd.concat(test, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12500\n",
       "1    12500\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### sentiment count #####\n",
    "train['sentiment'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12500\n",
       "1    12500\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['sentiment'].value_counts() # We can see that the dataset is balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the both the training dataset and test dataset are balanced, with 12500 positives and 12500 negatives\n",
    "in each dataset perspectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: nltk in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied, skipping upgrade: click in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: regex in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (2020.5.7)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (4.46.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user -U nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: numpy in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (1.18.4)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user -U numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### text normalization #####\n",
    "#Tokenization of text\n",
    "tokenizer = ToktokTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Removing html strips and noise text #####\n",
    "#Removing the html strips\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply function on review column\n",
    "train['Review'] = train['Review'].apply(denoise_text)\n",
    "test['Review'] = test['Review'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Removing special characters #####\n",
    "#Define function for removing special characters \n",
    "def remove_special_characters(text, remove_digits=True):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "train['Review'] = train['Review'].apply(remove_special_characters)\n",
    "test['Review'] = test['Review'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### removing stopwords ##### \n",
    "#define stopword list \n",
    "stopword_list = ['that', 'when', 'did', 'now', 'is', 'ain', 'its', \"she's\", 'having', 'to',\n",
    "                 're', 'we', 'further', 'they', 'why', \"needn't\", 'being', 'hasn', 'after',\n",
    "                 'there', 'until', \"it's\", 'own', 'as', \"shan't\", 'or', 'himself', 'these',\n",
    "                 'here', 'a', 'those', 'wasn', 'myself', 'not', 'again', 'have', 'ourselves',\n",
    "                 'nor', 'itself', 'both', \"you'll\", \"aren't\", 'because', \"wouldn't\", 'other',\n",
    "                 'at', 'her', \"didn't\", 'all', 'above', 'didn', \"mightn't\", 'what', 'any',\n",
    "                 'y', 'him', 'doesn', 'how', 'do', 'on', 'than', 'under', 'shan', 'me', 'few',\n",
    "                 'no', 'can', \"you'd\", 'out', 'couldn', 'needn', \"hadn't\", 'ma', 'd', 'our', \n",
    "                 'of', 'with', 'wouldn', 'hers', 'against', 'for', 'theirs', 'has', 'yourselves',\n",
    "                 'before', 'who', 'too', 's', 'each', 'had', 'ours', 'below', \"isn't\", 'while',\n",
    "                 'don', 'yourself', 'into', \"hasn't\", \"you're\", 'their', \"don't\", 'over', \"wasn't\",\n",
    "                 'yours', \"should've\", 'only', \"weren't\", 'between', 'themselves', 'once', 'be',\n",
    "                 'from', 'about', 'them', 'been', 'o', 'your', 'doing', 'am', 'should', 'does',\n",
    "                 'whom', 'my', 'he', 'it', 'an', 'in', 'same', 'very', 'his', 'and', 'most',\n",
    "                 've', \"haven't\", 'isn', \"mustn't\", 'weren', 't', 'aren', 'if', 'then', 'won',\n",
    "                 'through', 'haven', 'the', 'where', 'i', 'off', 'some', \"shouldn't\", 'mightn',\n",
    "                 'down', 'm', 'shouldn', 'which', \"that'll\", 'more', 'such', \"won't\", 'up', 'she',\n",
    "                 'was', 'herself', 'but', 'by', 'so', 'you', 'this', 'just', 'will', 'are', 'mustn',\n",
    "                 'during', \"doesn't\", 'hadn', 'll',\"you've\", 'were', \"couldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the stopwords\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW_cv_train: (25000, 4516501)\n",
      "BOW_cv_test: (25000, 4516501)\n"
     ]
    }
   ],
   "source": [
    "##### Bags of words model ##### \n",
    "#Count vectorizer for bag of words\n",
    "cv = CountVectorizer(min_df= 0, max_df = 1, binary = False, ngram_range = (1,3))\n",
    "#transformed train reviews\n",
    "cv_train_reviews = cv.fit_transform(train['Review'])\n",
    "#transformed test reviews\n",
    "cv_test_reviews = cv.transform(test['Review'])\n",
    "print('BOW_cv_train:', cv_train_reviews.shape) \n",
    "print('BOW_cv_test:', cv_test_reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf_train: (25000, 4516501)\n",
      "Tfidf_test: (25000, 4516501)\n"
     ]
    }
   ],
   "source": [
    "##### Term Frequency-Inverse Document Frequency model (TFIDF) ##### \n",
    "#Tfidf vectorizer\n",
    "tv = TfidfVectorizer(min_df = 0, max_df = 1, use_idf = True, ngram_range = (1,3))\n",
    "#transformed train reviews\n",
    "tv_train_reviews = tv.fit_transform(train['Review'])\n",
    "#transformed test reviews\n",
    "tv_test_reviews = tv.transform(test['Review'])\n",
    "print('Tfidf_train:',tv_train_reviews.shape) \n",
    "print('Tfidf_test:',tv_test_reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 1)\n",
      "(25000, 1)\n"
     ]
    }
   ],
   "source": [
    "##### Labeling the sentiment text ##### \n",
    "#labeling the sentient data\n",
    "lb = LabelBinarizer()\n",
    "#transformed sentiment train data \n",
    "sentiment_data = lb.fit_transform(train['sentiment'])\n",
    "print(sentiment_data.shape)\n",
    "#transformed sentiment test data \n",
    "sentiment_data = lb.fit_transform(test['sentiment'])\n",
    "print(sentiment_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting the sentiment data \n",
    "sentiment_train = train['sentiment']\n",
    "sentiment_test = test['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### logistic regression model for both bag of words and tfidf features #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "logit = LogisticRegression(penalty = 'l2', max_iter = 500, C = 1, random_state = 42)\n",
    "#Fitting the model for Bag of words\n",
    "logit_bow = logit.fit(cv_train_reviews, sentiment_train)\n",
    "print(logit_bow)\n",
    "#Fitting the model for tfidf features\n",
    "logit_tfidf = logit.fit(tv_train_reviews, sentiment_train)\n",
    "print(logit_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '1' '1' ... '0' '0' '1']\n",
      "['0' '1' '1' ... '0' '0' '1']\n"
     ]
    }
   ],
   "source": [
    "##### Logistic regression model performance on test dataset #####\n",
    "#Predicting the model for bag of words\n",
    "logit_bow_predict = logit.predict(cv_test_reviews)\n",
    "print(logit_bow_predict)\n",
    "##Predicting the model for tfidf features\n",
    "logit_tfidf_predict = logit.predict(tv_test_reviews)\n",
    "print(logit_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit_bow_score : 0.71356\n",
      "logit_tfidf_score : 0.71304\n"
     ]
    }
   ],
   "source": [
    "##### Accuracy of the model #####\n",
    "#bag of words\n",
    "logit_bow_score = accuracy_score(sentiment_test, logit_bow_predict)\n",
    "print(\"logit_bow_score :\", logit_bow_score)\n",
    "#tfidf \n",
    "logit_tfidf_score = accuracy_score(sentiment_test, logit_tfidf_predict)\n",
    "print(\"logit_tfidf_score :\", logit_tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.74      0.72     12500\n",
      "           0       0.72      0.69      0.71     12500\n",
      "\n",
      "    accuracy                           0.71     25000\n",
      "   macro avg       0.71      0.71      0.71     25000\n",
      "weighted avg       0.71      0.71      0.71     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### classification report #####\n",
    "#bag of words \n",
    "logit_bow_report = classification_report(sentiment_test, logit_bow_predict, target_names=['1','0'])\n",
    "print(logit_bow_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.74      0.72     12500\n",
      "           0       0.73      0.68      0.70     12500\n",
      "\n",
      "    accuracy                           0.71     25000\n",
      "   macro avg       0.71      0.71      0.71     25000\n",
      "weighted avg       0.71      0.71      0.71     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tfidf\n",
    "logit_tfidf_report = classification_report(sentiment_test, logit_tfidf_predict, target_names=['1','0'])\n",
    "print(logit_tfidf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9200 3300]\n",
      " [3861 8639]]\n",
      "[[9297 3203]\n",
      " [3971 8529]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "#confusion matrix for bag of words\n",
    "cnfmat_bow = confusion_matrix(sentiment_test, logit_bow_predict)\n",
    "print(cnfmat_bow)\n",
    "#confusion matrix for tfidf features\n",
    "cnfmat_tfidf = confusion_matrix(sentiment_test, logit_tfidf_predict)\n",
    "print(cnfmat_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Linear support vector machines for bag of words and tfidf features #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=500, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=42, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=500, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=42, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#training the linear svm\n",
    "svm = SGDClassifier(loss = 'hinge', max_iter = 500, random_state = 42)\n",
    "#fitting the svm for bag of words\n",
    "svm_bow = svm.fit(cv_train_reviews, sentiment_train)\n",
    "print(svm_bow)\n",
    "#fitting the svm for tfidf features\n",
    "svm_tfidf = svm.fit(tv_train_reviews, sentiment_train)\n",
    "print(svm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' '1' '1' ... '1' '0' '1']\n",
      "['1' '1' '1' ... '1' '1' '1']\n"
     ]
    }
   ],
   "source": [
    "##### Model performance on test data #####\n",
    "#bag of words\n",
    "svm_bow_predict = svm.predict(cv_test_reviews)\n",
    "print(svm_bow_predict)\n",
    "#tfidf\n",
    "svm_tfidf_predict = svm.predict(tv_test_reviews)\n",
    "print(svm_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_bow_score : 0.65712\n",
      "svm_tfidf_score : 0.50392\n"
     ]
    }
   ],
   "source": [
    "##Accuracy of the model\n",
    "#bag of words\n",
    "svm_bow_score = accuracy_score(sentiment_test, svm_bow_predict)\n",
    "print(\"svm_bow_score :\", svm_bow_score)\n",
    "#tfidf\n",
    "svm_tfidf_score = accuracy_score(sentiment_test, svm_tfidf_predict)\n",
    "print(\"svm_tfidf_score :\", svm_tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.39      0.53     12500\n",
      "           0       0.60      0.92      0.73     12500\n",
      "\n",
      "    accuracy                           0.66     25000\n",
      "   macro avg       0.72      0.66      0.63     25000\n",
      "weighted avg       0.72      0.66      0.63     25000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.01      0.02     12500\n",
      "           0       0.50      1.00      0.67     12500\n",
      "\n",
      "    accuracy                           0.50     25000\n",
      "   macro avg       0.75      0.50      0.34     25000\n",
      "weighted avg       0.75      0.50      0.34     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Classificiation report \n",
    "#Classification report for bag of words \n",
    "svm_bow_report=classification_report(sentiment_test, svm_bow_predict, target_names=['1','0'])\n",
    "print(svm_bow_report)\n",
    "#Classification report for tfidf features\n",
    "svm_tfidf_report=classification_report(sentiment_test, svm_tfidf_predict, target_names=['1','0'])\n",
    "print(svm_tfidf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4923  7577]\n",
      " [  995 11505]]\n",
      "[[   98 12402]\n",
      " [    0 12500]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix for bag of words\n",
    "cnfmat_bow = confusion_matrix(sentiment_test, svm_bow_predict)\n",
    "print(cnfmat_bow)\n",
    "#confusion matrix for tfidf features\n",
    "cnfmat_tfidf = confusion_matrix(sentiment_test, svm_tfidf_predict)\n",
    "print(cnfmat_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
